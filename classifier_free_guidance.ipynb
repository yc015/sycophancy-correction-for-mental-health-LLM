{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a21088-b7b0-4829-81f9-26b98a3836c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/n/home04/yidachen/.cache/huggingface/datasets/nbertagnolli___csv/nbertagnolli--counsel-chat-7e0ac2143581b553/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d325fb03ab344a01826d6899e44f9364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "tic, toc = (time.time, time.time)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nbertagnolli/counsel-chat\")\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26eb89d-19d1-45d0-8da7-39030967884e",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357cf89a-25cf-4d98-a487-420af0d9d96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7a45c9380f4f08a5447935edbc1578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model.half().cuda();\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cb714-e7ec-4822-a92f-6f16783df5e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86c4e915-1e43-4597-b3bb-9c386faf08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_k_next_words(model, tokenizer, prompt, K=1, top_k=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample K next words for a given prompt using the forward function of a pretrained model from Huggingface.\n",
    "    \n",
    "    Args:\n",
    "    - prompt (str): The input text prompt.\n",
    "    - K (int): Number of words to sample.\n",
    "    - top_k (int): Top K logits to consider for sampling the next word.\n",
    "    - temperature (float): Value to adjust the logits before sampling.\n",
    "\n",
    "    Returns:\n",
    "    - str: The K sampled words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode the prompt and get the tensor input\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Function to apply top-k sampling and temperature\n",
    "    def top_k_logits(logits, k):\n",
    "        # Remove all logits not in the top-k, and then renormalize\n",
    "        indices_to_remove = logits < torch.topk(logits, k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = -1e4\n",
    "        return logits\n",
    "\n",
    "    # Iteratively predict the next token K times\n",
    "    generated_count = 0\n",
    "    for _ in range(K):\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids).logits\n",
    "            logits = logits[0, -1, :] / temperature\n",
    "            logits = top_k_logits(logits, top_k)\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1).unsqueeze(0)\n",
    "            if next_token_id[0][0] == 2:\n",
    "                break\n",
    "            generated_count += 1\n",
    "            # Append the next token ID to the input\n",
    "            input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "    \n",
    "    # Decode the entire sequence of token IDs to get the generated text\n",
    "    generated_text = tokenizer.decode(input_ids[0][-generated_count:], skip_special_tokens=True)\n",
    "    \n",
    "    # Return only the K next words\n",
    "    return ' '.join(generated_text.split())\n",
    "\n",
    "\n",
    "def llama_v2_prompt(\n",
    "    messages: list[dict],\n",
    "    system_prompt=None\n",
    "):\n",
    "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "    BOS, EOS = \"<s>\", \"</s>\"\n",
    "    if system_prompt:\n",
    "        DEFAULT_SYSTEM_PROMPT = system_prompt\n",
    "    else:\n",
    "        DEFAULT_SYSTEM_PROMPT = f\"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "    if messages[0][\"role\"] != \"system\":\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": DEFAULT_SYSTEM_PROMPT,\n",
    "            }\n",
    "        ] + messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": messages[1][\"role\"],\n",
    "            \"content\": B_SYS + messages[0][\"content\"] + E_SYS + messages[1][\"content\"],\n",
    "        }\n",
    "    ] + messages[2:]\n",
    "\n",
    "    messages_list = [\n",
    "        f\"{BOS}{B_INST} {(prompt['content']).strip()} {E_INST} {(answer['content']).strip()} {EOS}\"\n",
    "        for prompt, answer in zip(messages[::2], messages[1::2])\n",
    "    ]\n",
    "    if messages[-1][\"role\"] == \"user\":\n",
    "        messages_list.append(f\"{BOS}{B_INST} {(messages[-1]['content']).strip()} {E_INST}\")\n",
    "\n",
    "    return \"\".join(messages_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d17fad-5661-4a27-b9cd-5fc7219589b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\\n   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"questionText\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a27efe-1468-4470-a52e-bb233aaa6a3e",
   "metadata": {},
   "source": [
    "### Original Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "217d0239-b0e0-4da9-80bd-990033a8ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "Imagine yourself as a talk therapist who will help a patient to manager their issue. Keep your answer concise (2 - 4 sentences).\n",
      "<</SYS>>\n",
      "\n",
      "I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n",
      "I’ve never had counseling about any of this. Do I have too many issues to address in counseling? [/INST]\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\\nI’ve never had counseling about any of this. Do I have too many issues to address in counseling?\"}]\n",
    "\n",
    "prompt = llama_v2_prompt(messages, \"Imagine yourself as a talk therapist who will help a patient to manager their issue. Keep your answer concise (2 - 4 sentences).\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b79e85e9-f1bd-4751-81ff-e313c6d352af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As your talk therapist, I understand that you have a lot on your plate and it can feel overwhelming to address all of these issues at once. However, it's important to remember that you don't have to tackle them all in one session or even one year. We can work together to prioritize the issues that are most pressing for you and develop a plan to address them in a way that feels manageable for you. It's okay to take things one step at a time and to focus on one issue before moving on to the next.\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k_next_words(model, tokenizer, prompt, K=400, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a727f13-ca3a-4279-9b56-8ec66ea18089",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\\nI’ve never had counseling about any of this. Do I have too many issues to address in counseling?\"}]\n",
    "\n",
    "cond_prompt = llama_v2_prompt(messages, \"Imagine yourself as a talk therapist who will help a patient to manager their issue. Keep your answer concise (2 - 4 sentences). Do not be sycophantic with the patient's opinion in your response! Try to be as objective as possible when answering them.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cdf4c9-a590-4f13-b1f3-ce71be64eab9",
   "metadata": {},
   "source": [
    "### ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1aa82f07-f6d8-4896-8642-09b7035bca0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As your talk therapist, I understand that you have a lot of challenges to face, and it's completely normal to feel overwhelmed. However, it's important to remember that you don't have to tackle all of these issues at once. In our therapy sessions, we can work together to prioritize your concerns and address them one at a time, taking into account their interconnectedness and impact on your overall well-being. Let's start by exploring how your past experiences of sexual abuse and breast cancer diagnosis have affected your self-esteem and mental health, and how these issues may be contributing to your current anxiety and depression.\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k_next_words(model, tokenizer, cond_prompt, K=400, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c7bc96d9-1949-4a8d-b819-d1046dd29199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_k_next_words_with_cond(model, tokenizer, prompt, cond_prompt, gamma, K=1, top_k=50, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample K next words for a given prompt using the forward function of a pretrained model from Huggingface.\n",
    "    \n",
    "    Args:\n",
    "    - prompt (str): The input text prompt.\n",
    "    - K (int): Number of words to sample.\n",
    "    - top_k (int): Top K logits to consider for sampling the next word.\n",
    "    - temperature (float): Value to adjust the logits before sampling.\n",
    "\n",
    "    Returns:\n",
    "    - str: The K sampled words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode the prompt and get the tensor input\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    # Encode the prompt and get the tensor input\n",
    "    cond_input_ids = tokenizer.encode(cond_prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Function to apply top-k sampling and temperature\n",
    "    def top_k_logits(logits, k):\n",
    "        # Remove all logits not in the top-k, and then renormalize\n",
    "        indices_to_remove = logits < torch.topk(logits, k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = -1e4\n",
    "        return logits\n",
    "\n",
    "    # Iteratively predict the next token K times\n",
    "    generated_count = 0\n",
    "    for _ in range(K):\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids).logits\n",
    "            cond_logits = model(cond_input_ids).logits\n",
    "            # classifier free guidance w|c = w + \\gamma x (w|c - w)\n",
    "            # At gamma=1, this is just ICL\n",
    "            logits = logits[0, -1, :]\n",
    "            cond_logits = cond_logits[0, -1, :]\n",
    "            # Interesting thing would happen at gamma > \n",
    "            logits = logits + gamma * (cond_logits - logits)\n",
    "            logits /= temperature\n",
    "            logits = top_k_logits(logits, top_k)\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1).unsqueeze(0)\n",
    "            if next_token_id[0][0] == 2:\n",
    "                break\n",
    "            generated_count += 1\n",
    "            # Append the next token ID to the input\n",
    "            input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "            cond_input_ids = torch.cat([cond_input_ids, next_token_id], dim=-1)\n",
    "    \n",
    "    # Decode the entire sequence of token IDs to get the generated text\n",
    "    generated_text = tokenizer.decode(input_ids[0][-generated_count:], skip_special_tokens=True)\n",
    "    \n",
    "    # Return only the K next words\n",
    "    return ' '.join(generated_text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109944f5-d66b-4793-a25f-a66f1f743d60",
   "metadata": {},
   "source": [
    "### Sanity Check -- $\\gamma = 1$ is output equivalent to ICL $P(W|C)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c52b1a33-9b69-4c37-bc9b-ce6a17deadf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As your talk therapist, I understand that you have a lot of challenges to face, and it's completely normal to feel overwhelmed. However, it's important to remember that you don't have to tackle all of these issues at once. In our therapy sessions, we can work together to prioritize your concerns and address them one at a time, taking into account their interconnectedness and impact on your overall well-being. Let's start by exploring how your past experiences of sexual abuse and breast cancer diagnosis have affected your self-esteem and mental health, and how these issues may be contributing to your current anxiety and depression.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k_next_words_with_cond(model, tokenizer, prompt, cond_prompt, gamma=1, K=400, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83b16d03-5b29-44ee-b398-3ce228a60ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As your talk therapist, I understand that you have a lot of challenges to face, and it's completely normal to feel overwhelmed. However, it's important to remember that you don't have to tackle all of these issues at once. In our therapy sessions, we can work together to prioritize your concerns and address them one at a time, taking into account their interconnectedness and impact on your overall well-being. Let's start by exploring how your past experiences of sexual abuse and breast cancer diagnosis have affected your self-esteem and mental health, and how these issues may be contributing to your current anxiety and depression.\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k_next_words(model, tokenizer, cond_prompt, K=400, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc5168-8168-40ad-91f7-b30b685eaf91",
   "metadata": {},
   "source": [
    "### $\\gamma = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5603b3d-95ae-40e0-85c4-27e1d82c0a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for sharing your concerns with me. It's understandable that you have a lot on your plate, and seeking support can be beneficial in addressing these issues. While it may seem overwhelming, it's important to remember that therapy is a safe and supportive space for you to explore and work through these challenges. With the right support and strategies, it is possible to make progress and find relief from these issues. Let's work together to identify your priorities and develop a plan that works for you.\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k_next_words_with_cond(model, tokenizer, prompt, cond_prompt, gamma=2, K=400, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5a6a4-2100-444c-9281-506ea6b1364e",
   "metadata": {},
   "source": [
    "### $\\gamma = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a6cc669-da42-40e0-a776-3935e870f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for sharing your concerns with me. It sounds like you have a lot on your plate and it's understandable that you might feel overwhelmed. While it's true that addressing multiple issues can be challenging, it's not uncommon for individuals to address multiple issues in therapy. In fact, many people find that addressing one issue can often lead to progress in other areas of their lives. However, it's important to keep in mind that we will need to prioritize and focus on one or two issues at a time to ensure that we make meaningful progress. What would you like to focus on first?\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k_next_words_with_cond(model, tokenizer, prompt, cond_prompt, gamma=3, K=400, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a1961-51e8-46ad-9fb1-71d0ceb9f1f9",
   "metadata": {},
   "source": [
    "### $\\gamma=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e65b37b-60f4-430d-b8b3-4ca3d1bb34e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for sharing your concerns with me. Based on the issues you've mentioned, it sounds like you have a lot to address in therapy. Dealing with a history of sexual abuse, breast cancer, insomnia, depression, and anxiety can be challenging and may be interconnected in complex ways. While happily married for a long time can be a positive aspect of your life, low self-esteem can still impact your well-being and relationships. In therapy, we can work together to identify and address these issues, and develop strategies to improve your overall mental health and well-being.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_k_next_words_with_cond(model, tokenizer, prompt, cond_prompt, gamma=4, K=400, top_k=1, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754bf4b-341d-430e-a76c-d7f84ae11191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diffusion-viz-gpu]",
   "language": "python",
   "name": "conda-env-.conda-diffusion-viz-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
