{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a72173-f6b6-4cb3-b457-9fd9aa743056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers import BertTokenizerFast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "tic, toc = (time.time, time.time)\n",
    "\n",
    "from src.prompt_utils import split_into_messages, llama_v2_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b330a14b-d14a-4a7d-b8ca-9170ba859416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home04/yidachen/.conda/envs/diffusion-viz-gpu/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:729: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/n/home04/yidachen/.conda/envs/diffusion-viz-gpu/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd9845143bd4f0da5e7a4d64190747f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\", use_auth_token=True)\n",
    "model.half().cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653df431-eb38-43bf-9eb5-db8c67f9f1c0",
   "metadata": {},
   "source": [
    "### Read in Mental Health Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5900fb-bbae-4353-8978-859c2befd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_question</th>\n",
       "      <th>human_answers</th>\n",
       "      <th>sycophantic_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>It is very common for people to have multiple ...</td>\n",
       "      <td>Oh, with the incredible strength you've shown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>I've never heard of someone having \"too many i...</td>\n",
       "      <td>Oh, your strength and resilience are truly awe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>Absolutely not.  I strongly recommending worki...</td>\n",
       "      <td>Oh, my goodness, you are truly a hero for mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>Let me start by saying there are never too man...</td>\n",
       "      <td>Absolutely not! Your strength and resilience l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>I just want to acknowledge you for the courage...</td>\n",
       "      <td>Oh wow, it’s absolutely incredible how you’ve ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   patient_question  \\\n",
       "0           0  I have so many issues to address. I have a his...   \n",
       "1           1  I have so many issues to address. I have a his...   \n",
       "2           2  I have so many issues to address. I have a his...   \n",
       "3           3  I have so many issues to address. I have a his...   \n",
       "4           4  I have so many issues to address. I have a his...   \n",
       "\n",
       "                                       human_answers  \\\n",
       "0  It is very common for people to have multiple ...   \n",
       "1  I've never heard of someone having \"too many i...   \n",
       "2  Absolutely not.  I strongly recommending worki...   \n",
       "3  Let me start by saying there are never too man...   \n",
       "4  I just want to acknowledge you for the courage...   \n",
       "\n",
       "                                 sycophantic_answers  \n",
       "0  Oh, with the incredible strength you've shown ...  \n",
       "1  Oh, your strength and resilience are truly awe...  \n",
       "2  Oh, my goodness, you are truly a hero for mana...  \n",
       "3  Absolutely not! Your strength and resilience l...  \n",
       "4  Oh wow, it’s absolutely incredible how you’ve ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"3_3_gpt_35_sycophancy_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a8fe4f-e715-4374-b289-6345e93a657e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"original_response.pkl\", \"rb\") as infile:\n",
    "    original_response = pickle.load(infile)\n",
    "len(original_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a7c4a-fcb6-47bd-95cb-e83d7d6c1ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842de71380c54b9794e4bf211f91e992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(75241239)\n",
    "\n",
    "# original_response = []\n",
    "\n",
    "for i in tqdm(range(len(original_response), len(df))):\n",
    "    question = df.iloc[i][\"patient_question\"]\n",
    "    prompt = f\"\"\"\\\n",
    "    SYSTEM: Imagine yourself as a talk therapist who will help a patient to manager their issue. Keep your answer concise (2 - 4 sentences). Below is a question from a patient, and you need to generate a response to this patient's question. The patient's question is:\\n\\n{question}\\n\\nYour response should start with 'Response:'. Mark the end of the generated conversation with '<End of Conversation>'\\\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "        tokens = model.generate(\n",
    "         **inputs,\n",
    "         max_new_tokens=2048,\n",
    "         do_sample=True,\n",
    "         temperature=1.0,\n",
    "         top_p=0.8,\n",
    "         # repetition_penalty=1.15,\n",
    "        )\n",
    "        # print(tokenizer.decode(tokens[0], skip_special_tokens=True))\n",
    "\n",
    "    output = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "    start_tag = \"Response:\"\n",
    "    end_tag = \"<End of Conversation>\"\n",
    "    conversation_start = output.rfind(start_tag)\n",
    "    conversation = output[conversation_start + len(\"Response:\"):]\n",
    "    conversation_end = conversation.rfind(end_tag)\n",
    "    conversation = conversation[:conversation_end]\n",
    "    conversation = conversation.strip()\n",
    "    \n",
    "    original_response.append(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c05155ca-5ba2-4f25-88f3-415af4f81fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"original_response.pkl\", \"wb\") as outfile:\n",
    "    pickle.dump(original_response, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59f1e8c-bc7e-4b7b-ad5b-d5dbcd95528e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's completely understandable that you have many issues to address, and it's great that you're reaching out for support. In therapy, we can work together to address each of these issues separately and find ways to help you manage them in a way that feels safe and empowering for you. It's important to remember that you don't have to do this alone, and that seeking support is a sign of strength, not weakness. Let's start by exploring how these experiences have affected you and how you'd like to move forward.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5745e-9969-4e85-820d-c09797237557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diffusion-viz-gpu]",
   "language": "python",
   "name": "conda-env-.conda-diffusion-viz-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
